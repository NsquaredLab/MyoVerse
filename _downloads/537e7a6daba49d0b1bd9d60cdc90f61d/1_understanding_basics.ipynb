{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Transform Basics\n\nThis example introduces the transform system - the core building block for\ndata processing in MyoVerse. Transforms use PyTorch named tensors for\ndimension-aware operations that run on both CPU and GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Data\nWe load EMG data from a pickle file and wrap it as a named tensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport myoverse\n\n# Get the path to the data file\n# Find data directory relative to myoverse package (works in all contexts)\nimport myoverse\n_pkg_dir = Path(myoverse.__file__).parent.parent\nDATA_DIR = _pkg_dir / \"examples\" / \"data\"\nif not DATA_DIR.exists():\n    # Fallback for editable installs or different layouts\n    DATA_DIR = Path.cwd() / \"examples\" / \"data\"\n\nwith open(DATA_DIR / \"emg.pkl\", \"rb\") as f:\n    emg_data = pkl.load(f)\n\nprint(\"EMG data loaded successfully:\")\nprint(f\"Tasks available: {list(emg_data.keys())}\")\nfor task, data in emg_data.items():\n    print(f\"\\tTask '{task}': shape {data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Named Tensors\nNamed tensors have dimension names, making operations explicit.\nNo more guessing which axis is which!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SAMPLING_FREQ = 2044\n\n# Create named tensor with myoverse\nemg = myoverse.emg_tensor(emg_data[\"1\"], fs=SAMPLING_FREQ)\n\nprint(f\"\\nNamed Tensor:\")\nprint(f\"\\tDimension names: {emg.names}\")\nprint(f\"\\tShape: {emg.shape}\")\nprint(f\"\\tDevice: {emg.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Raw Data\nVisualize all channels of the raw EMG signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.style.use(\"fivethirtyeight\")\nplt.figure(figsize=(12, 6))\n\nn_channels = emg.shape[0]\nfor channel in range(n_channels):\n    plt.plot(emg[channel].rename(None).numpy(), color=\"black\", alpha=0.1)\n\nplt.title(\"Raw EMG Data\")\nplt.ylabel(\"Amplitude (a.u.)\")\nn_samples = emg.shape[1]\nplt.xticks(\n    np.arange(0, n_samples + 1, SAMPLING_FREQ).astype(int),\n    np.arange(0, n_samples / SAMPLING_FREQ + 1, 1).astype(int),\n)\nplt.xlabel(\"Time (s)\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dimension-Aware Transforms\nTransforms explicitly specify which dimension they operate on.\nNo more axis=-1 guessing!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Lowpass, Compose\n\n# Create a lowpass filter - explicitly operates on \"time\" dimension\nlowpass = Lowpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\")\nprint(f\"\\nTransform: {lowpass}\")\n\n# Apply it - dimension names are preserved!\nfiltered_emg = lowpass(emg)\nprint(f\"Input names:  {emg.names}\")\nprint(f\"Output names: {filtered_emg.names}\")\nprint(f\"Dimensions are preserved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compose: Chaining Transforms\nCompose lets you chain multiple transforms together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Highpass, Rectify\n\n# Each transform specifies its operating dimension\nfeature_pipeline = Compose([\n    Highpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    Rectify(),\n])\n\nprint(f\"\\nCompose: {feature_pipeline}\")\n\nfeatures = feature_pipeline(emg)\nprint(f\"Output names: {features.names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Raw vs Filtered\nLet's visualize the effect of the lowpass filter on one channel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\nchannel = 0\n\n# Raw EMG\nplt.subplot(2, 1, 1)\nplt.plot(emg[channel].rename(None).numpy(), label=\"Raw EMG\")\nplt.title(f\"Raw EMG - Channel {channel + 1}\")\nplt.ylabel(\"Amplitude (a.u.)\")\nplt.legend()\n\n# Filtered EMG\nplt.subplot(2, 1, 2)\nplt.plot(filtered_emg[channel].rename(None).numpy(), label=\"Lowpass Filtered (20 Hz)\")\nplt.title(f\"Lowpass Filtered EMG - Channel {channel + 1}\")\nplt.ylabel(\"Amplitude (a.u.)\")\nplt.xlabel(\"Samples\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Representation with Stack\nStack applies multiple transforms and combines results along a new dimension.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Stack, Identity\n\n# Create raw + filtered representations\nmulti_repr = Stack({\n    \"raw\": Identity(),\n    \"filtered\": Lowpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n}, dim=\"representation\")\n\n# Apply - returns stacked tensor with new dimension!\nstacked = multi_repr(emg)\nprint(f\"\\nStack output:\")\nprint(f\"\\tNames: {stacked.names}\")\nprint(f\"\\tShape: {stacked.shape}\")\nprint(\"\\t(representation=2, channel, time)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Pipeline: Stack in Compose\nCombine Stack in a Compose for a clean workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dual_representation = Compose([\n    Stack({\n        \"raw\": Identity(),\n        \"filtered\": Lowpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    }, dim=\"representation\"),\n])\n\noutput = dual_representation(emg)\nprint(f\"\\nDual representation pipeline:\")\nprint(f\"\\tInput:  {emg.names} {emg.shape}\")\nprint(f\"\\tOutput: {output.names} {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing Dual Representation\nPlot both representations for one channel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\nchannel = 0\n\nplt.subplot(2, 1, 1)\nplt.plot(output[0, channel].rename(None).numpy(), label=\"Raw\")\nplt.title(f\"Raw Representation - Channel {channel + 1}\")\nplt.ylabel(\"Amplitude (a.u.)\")\nplt.legend()\n\nplt.subplot(2, 1, 2)\nplt.plot(output[1, channel].rename(None).numpy(), label=\"Filtered (20 Hz)\")\nplt.title(f\"Filtered Representation - Channel {channel + 1}\")\nplt.ylabel(\"Amplitude (a.u.)\")\nplt.xlabel(\"Samples\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other Useful Transforms\nMyoVerse includes many transforms for signal processing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Index, Mean, ZScore\n\n# Index: select specific elements by dimension name\nselect_channels = Index(indices=slice(0, 64), dim=\"channel\")\nsubset = select_channels(emg)\nprint(f\"\\nIndex (first 64 channels): {emg.names}{tuple(emg.shape)} -> {subset.names}{tuple(subset.shape)}\")\n\n# Mean: average over a dimension\nmean = Mean(dim=\"time\")\naveraged = mean(emg)\nprint(f\"Mean over time: {emg.names}{tuple(emg.shape)} -> {averaged.names}{tuple(averaged.shape)}\")\n\n# ZScore: normalize over a dimension\nzscore = ZScore(dim=\"time\")\nnormalized = zscore(emg)\nnorm_data = normalized.rename(None)\nprint(f\"ZScore: mean={float(norm_data.mean()):.6f}, std={float(norm_data.std()):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPU Acceleration\nMove to GPU for faster processing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n    emg_gpu = emg.cuda()\n    print(f\"\\nEMG on GPU: {emg_gpu.device}\")\n\n    # All transforms work on GPU\n    filtered_gpu = lowpass(emg_gpu)\n    print(f\"Filtered on GPU: {filtered_gpu.device}\")\nelse:\n    print(\"\\nCUDA not available - using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\nKey concepts:\n\n1. **Named Tensors** - Dimension names via `myoverse.emg_tensor()`\n2. **Transforms** - Dimension-aware: `Lowpass(cutoff=20, fs=2048, dim=\"time\")`\n3. **Compose** - Chain transforms together (from torchvision)\n4. **Stack** - Create multiple representations along new dimension\n\nBenefits of dimension-aware transforms:\n- Self-documenting: `dim=\"time\"` vs `axis=-1`\n- Safe: won't accidentally filter along wrong axis\n- Composable: dimensions are preserved through pipelines\n- Fast: runs on CPU or GPU\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}