{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Temporal Signal Processing\n\nThis example demonstrates temporal transforms for EMG signal processing.\nAll transforms work with PyTorch named tensors for dimension-aware operations\nthat run on both CPU and GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Data\nLoad EMG data and wrap as a named tensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport torch\nimport myoverse\n\n# Get the path to the data file\n# Find data directory relative to myoverse package (works in all contexts)\nimport myoverse\n_pkg_dir = Path(myoverse.__file__).parent.parent\nDATA_DIR = _pkg_dir / \"examples\" / \"data\"\nif not DATA_DIR.exists():\n    DATA_DIR = Path.cwd() / \"examples\" / \"data\"\n\nwith open(DATA_DIR / \"emg.pkl\", \"rb\") as f:\n    emg_data = pkl.load(f)\n\n# Create named tensor with myoverse\nSAMPLING_FREQ = 2044\nemg = myoverse.emg_tensor(emg_data[\"1\"], fs=SAMPLING_FREQ)\n\nprint(f\"EMG data loaded: {emg.names} {emg.shape}\")\nprint(f\"Device: {emg.device}\")\n\n# Use fivethirtyeight style for all plots\nplt.style.use(\"fivethirtyeight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing Raw Signal\nPlot one channel of the raw EMG signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "channel = 0\ntime_sec = 5\nsamples = int(time_sec * SAMPLING_FREQ)\n\nplt.figure(figsize=(12, 4))\nplt.plot(emg[channel, :samples].rename(None).numpy())\nplt.title(\"Raw EMG Signal (Channel 0)\")\nplt.xlabel(\"Samples\")\nplt.ylabel(\"Amplitude\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Frequency Filtering\nBandpass filtering to extract the useful EMG frequency band (20-450 Hz).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Bandpass, Compose\n\n# Create bandpass filter - explicitly operates on \"time\" dimension\nbandpass = Bandpass(low=20, high=450, fs=SAMPLING_FREQ, dim=\"time\")\nprint(f\"Transform: {bandpass}\")\n\n# Apply the filter\nfiltered = bandpass(emg)\nprint(f\"Output names: {filtered.names}\")\n\n# Visualize\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(emg[channel, :samples].rename(None).numpy())\nplt.title(\"Raw EMG Signal\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(2, 1, 2)\nplt.plot(filtered[channel, :samples].rename(None).numpy())\nplt.title(\"Bandpass Filtered EMG (20-450 Hz)\")\nplt.xlabel(\"Samples\")\nplt.ylabel(\"Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Rectification\nFull-wave rectification converts negative values to positive.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Rectify\n\n# Rectification is element-wise\nrectify = Rectify()\nrectified = rectify(filtered)\n\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(filtered[channel, :samples].rename(None).numpy())\nplt.title(\"Bandpass Filtered EMG\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(2, 1, 2)\nplt.plot(rectified[channel, :samples].rename(None).numpy())\nplt.title(\"Rectified EMG\")\nplt.xlabel(\"Samples\")\nplt.ylabel(\"Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. RMS Feature Extraction\nRoot Mean Square (RMS) represents signal power over time windows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import RMS\n\n# RMS with sliding window - operates on \"time\" dimension\nrms = RMS(window_size=200, dim=\"time\")  # ~100ms window\nrms_feature = rms(rectified)\n\nprint(f\"RMS output shape: {rms_feature.shape}\")  # Reduced time dimension\n\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(rectified[channel, :samples].rename(None).numpy(), alpha=0.7)\nplt.title(\"Rectified EMG\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(2, 1, 2)\n# Adjust for reduced samples\nrms_samples = min(samples // 200, rms_feature.shape[-1])\nplt.plot(rms_feature[channel, :rms_samples].rename(None).numpy(), linewidth=2)\nplt.title(\"RMS Envelope (200 sample window)\")\nplt.xlabel(\"Windows\")\nplt.ylabel(\"RMS Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Composes: Chaining Transforms\nCombine multiple transforms into a preprocessing pipeline.\nUses torchvision.transforms.Compose under the hood.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline = Compose([\n    Bandpass(low=20, high=450, fs=SAMPLING_FREQ, dim=\"time\"),\n    Rectify(),\n    RMS(window_size=200, dim=\"time\"),\n])\n\nprint(f\"Compose: {pipeline}\")\n\n# Apply entire pipeline\nprocessed = pipeline(emg)\nprint(f\"Input: {emg.names} {emg.shape}\")\nprint(f\"Output: {processed.names} {processed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Mean Absolute Value (MAV)\nAnother common EMG feature - moving average of rectified signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import MAV\n\nmav = MAV(window_size=200, dim=\"time\")\nmav_feature = mav(rectified)\n\n# Compare RMS and MAV\nplt.figure(figsize=(12, 6))\n\n# Normalize for comparison\nrms_data = rms_feature[channel].rename(None)\nmav_data = mav_feature[channel].rename(None)\nrms_norm = (rms_data - rms_data.min()) / (rms_data.max() - rms_data.min())\nmav_norm = (mav_data - mav_data.min()) / (mav_data.max() - mav_data.min())\n\nn_windows = min(50, len(rms_norm))\nplt.plot(rms_norm[:n_windows].numpy(), label=\"RMS\", linewidth=2)\nplt.plot(mav_norm[:n_windows].numpy(), label=\"MAV\", linewidth=2, alpha=0.8)\nplt.title(\"RMS vs MAV Features (Normalized)\")\nplt.xlabel(\"Windows\")\nplt.ylabel(\"Normalized Amplitude\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Lowpass vs Highpass\nCompare different filter types.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Highpass, Lowpass\n\nlowpass = Lowpass(cutoff=50, fs=SAMPLING_FREQ, dim=\"time\")\nhighpass = Highpass(cutoff=50, fs=SAMPLING_FREQ, dim=\"time\")\n\nlow_filtered = lowpass(emg)\nhigh_filtered = highpass(emg)\n\nplt.figure(figsize=(12, 10))\n\nplt.subplot(3, 1, 1)\nplt.plot(emg[channel, :samples].rename(None).numpy())\nplt.title(\"Raw EMG\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(3, 1, 2)\nplt.plot(low_filtered[channel, :samples].rename(None).numpy())\nplt.title(\"Lowpass Filtered (< 50 Hz)\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(3, 1, 3)\nplt.plot(high_filtered[channel, :samples].rename(None).numpy())\nplt.title(\"Highpass Filtered (> 50 Hz)\")\nplt.xlabel(\"Samples\")\nplt.ylabel(\"Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Normalization\nZ-score normalization for consistent scaling.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import ZScore\n\n# Z-score normalize each channel over time\nzscore = ZScore(dim=\"time\")\nnormalized = zscore(processed)\n\nprocessed_data = processed.rename(None)\nprint(f\"Before normalization:\")\nprint(f\"\\tMean: {float(processed_data.mean()):.4f}\")\nprint(f\"\\tStd:  {float(processed_data.std()):.4f}\")\n\nnormalized_data = normalized.rename(None)\nprint(f\"\\nAfter normalization:\")\nprint(f\"\\tMean: {float(normalized_data.mean()):.6f}\")\nprint(f\"\\tStd:  {float(normalized_data.std()):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Data Augmentation\nAdd noise and warping for training augmentation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import GaussianNoise, MagnitudeWarp\n\n# Add Gaussian noise\nnoise_aug = GaussianNoise(std=0.1)\nnoisy = noise_aug(emg)\n\n# Magnitude warping\nwarp_aug = MagnitudeWarp(sigma=0.2, n_knots=4, dim=\"time\")\nwarped = warp_aug(emg)\n\nplt.figure(figsize=(12, 10))\n\nplt.subplot(3, 1, 1)\nplt.plot(emg[channel, :samples].rename(None).numpy())\nplt.title(\"Original EMG\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(3, 1, 2)\nplt.plot(noisy[channel, :samples].rename(None).numpy())\nplt.title(\"With Gaussian Noise\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(3, 1, 3)\nplt.plot(warped[channel, :samples].rename(None).numpy())\nplt.title(\"With Magnitude Warping\")\nplt.xlabel(\"Samples\")\nplt.ylabel(\"Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Multi-feature Extraction\nExtract multiple features using Stack.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Stack\n\n# Create multiple feature extractors\nfeature_pipeline = Compose([\n    Bandpass(low=20, high=450, fs=SAMPLING_FREQ, dim=\"time\"),\n    Rectify(),\n])\n\n# Apply bandpass + rectify first\npreprocessed = feature_pipeline(emg)\n\n# Then extract multiple features\nfeatures = Stack({\n    \"rms\": RMS(window_size=200, dim=\"time\"),\n    \"mav\": MAV(window_size=200, dim=\"time\"),\n    \"var\": myoverse.transforms.VAR(window_size=200, dim=\"time\"),\n}, dim=\"feature\")\n\nmulti_features = features(preprocessed)\nprint(f\"Multi-feature output: {multi_features.names} {multi_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. GPU Acceleration\nMove data to GPU for faster processing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n    # Move to GPU\n    emg_gpu = emg.cuda()\n    print(f\"EMG on GPU: {emg_gpu.device}\")\n\n    # Apply pipeline on GPU\n    processed_gpu = pipeline(emg_gpu)\n    print(f\"Processed on GPU: {processed_gpu.device}\")\nelse:\n    print(\"CUDA not available - using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Creating Custom Transforms\nExtend the Transform base class for custom processing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Transform\n\nclass MedianFilter(Transform):\n    \"\"\"Custom median filter transform using PyTorch.\n\n    Parameters\n    ----------\n    kernel_size : int\n        Size of the median filter kernel. Must be odd.\n    dim : str\n        Dimension to filter along.\n    \"\"\"\n\n    def __init__(self, kernel_size: int = 5, dim: str = \"time\", **kwargs):\n        super().__init__(dim=dim, **kwargs)\n        if kernel_size % 2 == 0:\n            raise ValueError(\"Kernel size must be odd\")\n        self.kernel_size = kernel_size\n\n    def _apply(self, x: torch.Tensor) -> torch.Tensor:\n        from myoverse.transforms.base import get_dim_index\n        dim_idx = get_dim_index(x, self.dim)\n        names = x.names\n\n        x = x.rename(None)\n\n        # Unfold to get sliding windows\n        x_unfolded = x.unfold(dim_idx, self.kernel_size, 1)\n\n        # Compute median over the last dimension (the window)\n        result = x_unfolded.median(dim=-1).values\n\n        # Pad to maintain size\n        pad_total = self.kernel_size - 1\n        pad_before = pad_total // 2\n        pad_after = pad_total - pad_before\n\n        # Move target dim to last position for padding\n        result = result.movedim(dim_idx, -1)\n        original_shape = result.shape\n\n        # F.pad with mode='replicate' requires 3D+ input\n        # Reshape to 3D: (batch, 1, time)\n        result = result.reshape(-1, 1, result.shape[-1])\n        result = torch.nn.functional.pad(result, (pad_before, pad_after), mode='replicate')\n\n        # Restore original shape and move dim back\n        result = result.reshape(*original_shape[:-1], -1)\n        result = result.movedim(-1, dim_idx)\n\n        if names[0] is not None:\n            result = result.rename(*names)\n\n        return result\n\n# Use in a pipeline\ncustom_pipeline = Compose([\n    Bandpass(low=20, high=450, fs=SAMPLING_FREQ, dim=\"time\"),\n    MedianFilter(kernel_size=11, dim=\"time\"),\n    ZScore(dim=\"time\"),\n])\n\ncustom_output = custom_pipeline(emg)\nprint(f\"Custom pipeline output: {custom_output.names} {custom_output.shape}\")\n\n# Visualize\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(emg[channel, :samples].rename(None).numpy())\nplt.title(\"Raw EMG\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(2, 1, 2)\nplt.plot(custom_output[channel, :samples].rename(None).numpy())\nplt.title(\"Custom Compose (Bandpass + Median + ZScore)\")\nplt.xlabel(\"Samples\")\nplt.ylabel(\"Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\nKey temporal transforms:\n\n- **Bandpass/Lowpass/Highpass/Notch** - FFT-based frequency filtering\n- **Rectify** - Full-wave rectification\n- **RMS/MAV/VAR** - Sliding window feature extraction\n- **ZScore/MinMax** - Normalization\n- **GaussianNoise/MagnitudeWarp/TimeWarp** - Augmentation\n\nAll transforms:\n- Work with PyTorch named tensors\n- Are dimension-aware via the `dim` parameter\n- Run on both CPU and GPU\n- Can be combined with torchvision.transforms.Compose (or Compose)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}