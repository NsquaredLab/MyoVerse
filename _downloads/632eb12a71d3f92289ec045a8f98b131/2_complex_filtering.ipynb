{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Complex Filtering Pipelines\n\nThis example shows how to build complex filter pipelines with multiple\nrepresentations using the dimension-aware transform system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Data\nLoad EMG data and wrap as a named tensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport torch\nimport myoverse\n\n# Get the path to the data file\n# Find data directory relative to myoverse package (works in all contexts)\nimport myoverse\n_pkg_dir = Path(myoverse.__file__).parent.parent\nDATA_DIR = _pkg_dir / \"examples\" / \"data\"\nif not DATA_DIR.exists():\n    DATA_DIR = Path.cwd() / \"examples\" / \"data\"\n\nwith open(DATA_DIR / \"emg.pkl\", \"rb\") as f:\n    emg_data = pkl.load(f)\n\nSAMPLING_FREQ = 2048\nemg = myoverse.emg_tensor(emg_data[\"1\"], fs=SAMPLING_FREQ)\n\nprint(f\"EMG data loaded: {emg.names} {emg.shape}\")\n\nplt.style.use(\"fivethirtyeight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Pipeline: Highpass + Lowpass\nA common preprocessing sequence:\n1. Highpass filter (20 Hz) to remove DC and movement artifacts\n2. Lowpass filter (450 Hz) to remove high frequency noise\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Compose, Highpass, Lowpass\n\n# Preprocessing pipeline using Compose\npreprocess = Compose([\n    Highpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    Lowpass(cutoff=450, fs=SAMPLING_FREQ, dim=\"time\"),\n])\n\nfiltered = preprocess(emg)\nprint(f\"Preprocessed: {filtered.names} {filtered.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Representation with Stack\nOften we want multiple representations of the same signal.\nStack applies multiple transforms and combines them along a new dimension.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Identity, Stack\n\n# Create two representations:\n# - \"raw\": Just the preprocessed signal\n# - \"envelope\": Lowpass filtered version (smooth envelope)\n\ndual_repr = Stack({\n    \"raw\": Identity(),\n    \"envelope\": Lowpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n}, dim=\"representation\")\n\n# Apply to preprocessed data\nstacked = dual_repr(filtered)\nprint(f\"Stack output: {stacked.names} {stacked.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Pipeline: Preprocess + Stack\nCombine everything into one pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "complete_pipeline = Compose([\n    # Preprocessing\n    Highpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    Lowpass(cutoff=450, fs=SAMPLING_FREQ, dim=\"time\"),\n    # Multi-representation\n    Stack({\n        \"raw\": Identity(),\n        \"envelope\": Lowpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    }, dim=\"representation\"),\n])\n\noutput = complete_pipeline(emg)\nprint(f\"\\nComplete pipeline:\")\nprint(f\"\\tInput:  {emg.names} {emg.shape}\")\nprint(f\"\\tOutput: {output.names} {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the Pipeline Output\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "channel = 0\nsamples = 5000\n\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(output[0, channel, :samples].rename(None).numpy())\nplt.title(\"Raw (Bandpass Filtered)\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(2, 1, 2)\nplt.plot(output[1, channel, :samples].rename(None).numpy())\nplt.title(\"Envelope (Additional Lowpass)\")\nplt.xlabel(\"Samples\")\nplt.ylabel(\"Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complex Stacking: Multiple Feature Representations\nCreate multiple feature representations from the same input.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import Rectify\n\n# Stack with nested Compose for complex branches\nfeature_stack = Stack({\n    \"raw\": Identity(),\n    \"envelope\": Lowpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    \"rectified\": Compose([\n        Rectify(),\n        Lowpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    ]),\n}, dim=\"representation\")\n\n# Apply to preprocessed data\nstacked_features = feature_stack(filtered)\nprint(f\"Stacked features: {stacked_features.names} {stacked_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing Multiple Features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 10))\n\nnames = [\"raw\", \"envelope\", \"rectified\"]\nfor i, name in enumerate(names):\n    plt.subplot(3, 1, i + 1)\n    plt.plot(stacked_features[i, channel, :samples].rename(None).numpy())\n    plt.title(f\"{name.capitalize()} Representation\")\n    plt.ylabel(\"Amplitude\")\n    if i == 2:\n        plt.xlabel(\"Samples\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline with RMS Feature Extraction\nExtract RMS features from multiple representations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import RMS\n\nrms_pipeline = Compose([\n    # Preprocess\n    Highpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    # Multi-representation\n    Stack({\n        \"bandpass\": Identity(),\n        \"lowpass\": Lowpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    }, dim=\"representation\"),\n    # Apply RMS to both representations\n    RMS(window_size=100, dim=\"time\"),\n])\n\nrms_output = rms_pipeline(emg)\nprint(f\"RMS pipeline output: {rms_output.names} {rms_output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing RMS Features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Adjust samples for RMS output (reduced time dimension)\nrms_samples = min(samples // 100, rms_output.shape[-1])\n\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nplt.plot(rms_output[0, channel, :rms_samples].rename(None).numpy(), linewidth=2)\nplt.title(\"RMS of Bandpass Filtered Signal\")\nplt.ylabel(\"RMS Amplitude\")\n\nplt.subplot(2, 1, 2)\nplt.plot(rms_output[1, channel, :rms_samples].rename(None).numpy(), linewidth=2)\nplt.title(\"RMS of Lowpass Filtered Signal\")\nplt.xlabel(\"Windows\")\nplt.ylabel(\"RMS Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## All Channels Visualization\nPlot all channels to see the overall signal structure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_channels = min(64, rms_output.shape[1])\n\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 1, 1)\nfor ch in range(n_channels):\n    plt.plot(\n        rms_output[0, ch].rename(None).numpy(),\n        color=\"black\",\n        alpha=0.05,\n    )\nplt.title(\"RMS Features - All Channels (Bandpass)\")\nplt.ylabel(\"Amplitude\")\n\nplt.subplot(2, 1, 2)\nfor ch in range(n_channels):\n    plt.plot(\n        rms_output[1, ch].rename(None).numpy(),\n        color=\"black\",\n        alpha=0.05,\n    )\nplt.title(\"RMS Features - All Channels (Lowpass)\")\nplt.xlabel(\"Windows\")\nplt.ylabel(\"Amplitude\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Feature Extraction Pipeline\nA full pipeline with preprocessing, feature extraction, and normalization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from myoverse.transforms import ZScore\n\nfull_pipeline = Compose([\n    Highpass(cutoff=20, fs=SAMPLING_FREQ, dim=\"time\"),\n    Lowpass(cutoff=450, fs=SAMPLING_FREQ, dim=\"time\"),\n    Rectify(),\n    RMS(window_size=100, dim=\"time\"),\n    ZScore(dim=\"time\"),\n])\n\nfinal_output = full_pipeline(emg)\nprint(f\"Full pipeline output: {final_output.names} {final_output.shape}\")\n\n# Verify normalization\nfinal_data = final_output.rename(None)\nprint(f\"Mean: {float(final_data.mean()):.6f}, Std: {float(final_data.std()):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPU Acceleration\nAll pipelines work on GPU for faster processing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n    emg_gpu = emg.cuda()\n    print(f\"\\nEMG on GPU: {emg_gpu.device}\")\n\n    # Apply complete pipeline on GPU\n    output_gpu = complete_pipeline(emg_gpu)\n    print(f\"Output on GPU: {output_gpu.device}\")\nelse:\n    print(\"\\nCUDA not available - using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\nComplex pipelines are built by combining:\n\n1. **Compose** - Chain transforms sequentially (from torchvision)\n2. **Stack** - Create multiple representations along a new dimension\n3. **Identity** - Pass-through (useful in Stack for \"raw\" representation)\n\nKey patterns:\n\n```python\n# Sequential processing\nCompose([Transform1(), Transform2(), Transform3()])\n\n# Multi-representation (one input -> stacked output)\nStack({\n    \"name1\": Transform1(),\n    \"name2\": Transform2(),\n}, dim=\"representation\")\n\n# Complete pattern\nCompose([\n    Preprocess(),\n    Stack({\n        \"raw\": Identity(),\n        \"filtered\": FilterTransform(),\n    }, dim=\"representation\"),\n    PostProcess(),  # Applied to all representations\n])\n```\n\nAll transforms are dimension-aware - specify `dim=\"time\"` to be explicit\nabout which dimension is being processed.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}