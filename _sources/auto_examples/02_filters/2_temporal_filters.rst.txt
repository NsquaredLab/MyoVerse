
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/02_filters/2_temporal_filters.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_02_filters_2_temporal_filters.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_02_filters_2_temporal_filters.py:


Temporal Signal Processing
==========================

This example demonstrates temporal transforms for EMG signal processing.
All transforms work with PyTorch named tensors for dimension-aware operations
that run on both CPU and GPU.

.. GENERATED FROM PYTHON SOURCE LINES 11-14

Loading Data
------------
Load EMG data and wrap as a named tensor.

.. GENERATED FROM PYTHON SOURCE LINES 14-43

.. code-block:: Python


    import pickle as pkl
    from pathlib import Path

    import matplotlib.pyplot as plt
    import torch
    import myoverse

    # Get the path to the data file
    # Find data directory relative to myoverse package (works in all contexts)
    import myoverse
    _pkg_dir = Path(myoverse.__file__).parent.parent
    DATA_DIR = _pkg_dir / "examples" / "data"
    if not DATA_DIR.exists():
        DATA_DIR = Path.cwd() / "examples" / "data"

    with open(DATA_DIR / "emg.pkl", "rb") as f:
        emg_data = pkl.load(f)

    # Create named tensor with myoverse
    SAMPLING_FREQ = 2044
    emg = myoverse.emg_tensor(emg_data["1"], fs=SAMPLING_FREQ)

    print(f"EMG data loaded: {emg.names} {emg.shape}")
    print(f"Device: {emg.device}")

    # Use fivethirtyeight style for all plots
    plt.style.use("fivethirtyeight")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    EMG data loaded: ('channel', 'time') torch.Size([320, 20440])
    Device: cpu




.. GENERATED FROM PYTHON SOURCE LINES 44-47

Visualizing Raw Signal
----------------------
Plot one channel of the raw EMG signal.

.. GENERATED FROM PYTHON SOURCE LINES 47-59

.. code-block:: Python


    channel = 0
    time_sec = 5
    samples = int(time_sec * SAMPLING_FREQ)

    plt.figure(figsize=(12, 4))
    plt.plot(emg[channel, :samples].rename(None).numpy())
    plt.title("Raw EMG Signal (Channel 0)")
    plt.xlabel("Samples")
    plt.ylabel("Amplitude")
    plt.show()




.. image-sg:: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_001.png
   :alt: Raw EMG Signal (Channel 0)
   :srcset: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 60-63

1. Frequency Filtering
----------------------
Bandpass filtering to extract the useful EMG frequency band (20-450 Hz).

.. GENERATED FROM PYTHON SOURCE LINES 63-91

.. code-block:: Python


    from myoverse.transforms import Bandpass, Compose

    # Create bandpass filter - explicitly operates on "time" dimension
    bandpass = Bandpass(low=20, high=450, fs=SAMPLING_FREQ, dim="time")
    print(f"Transform: {bandpass}")

    # Apply the filter
    filtered = bandpass(emg)
    print(f"Output names: {filtered.names}")

    # Visualize
    plt.figure(figsize=(12, 8))

    plt.subplot(2, 1, 1)
    plt.plot(emg[channel, :samples].rename(None).numpy())
    plt.title("Raw EMG Signal")
    plt.ylabel("Amplitude")

    plt.subplot(2, 1, 2)
    plt.plot(filtered[channel, :samples].rename(None).numpy())
    plt.title("Bandpass Filtered EMG (20-450 Hz)")
    plt.xlabel("Samples")
    plt.ylabel("Amplitude")

    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_002.png
   :alt: Raw EMG Signal, Bandpass Filtered EMG (20-450 Hz)
   :srcset: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Transform: Bandpass(dim='time', low=20, high=450, fs=2044, order=4, Q=0.707)
    Output names: ('channel', 'time')




.. GENERATED FROM PYTHON SOURCE LINES 92-95

2. Rectification
----------------
Full-wave rectification converts negative values to positive.

.. GENERATED FROM PYTHON SOURCE LINES 95-118

.. code-block:: Python


    from myoverse.transforms import Rectify

    # Rectification is element-wise
    rectify = Rectify()
    rectified = rectify(filtered)

    plt.figure(figsize=(12, 8))

    plt.subplot(2, 1, 1)
    plt.plot(filtered[channel, :samples].rename(None).numpy())
    plt.title("Bandpass Filtered EMG")
    plt.ylabel("Amplitude")

    plt.subplot(2, 1, 2)
    plt.plot(rectified[channel, :samples].rename(None).numpy())
    plt.title("Rectified EMG")
    plt.xlabel("Samples")
    plt.ylabel("Amplitude")

    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_003.png
   :alt: Bandpass Filtered EMG, Rectified EMG
   :srcset: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 119-122

3. RMS Feature Extraction
-------------------------
Root Mean Square (RMS) represents signal power over time windows.

.. GENERATED FROM PYTHON SOURCE LINES 122-149

.. code-block:: Python


    from myoverse.transforms import RMS

    # RMS with sliding window - operates on "time" dimension
    rms = RMS(window_size=200, dim="time")  # ~100ms window
    rms_feature = rms(rectified)

    print(f"RMS output shape: {rms_feature.shape}")  # Reduced time dimension

    plt.figure(figsize=(12, 8))

    plt.subplot(2, 1, 1)
    plt.plot(rectified[channel, :samples].rename(None).numpy(), alpha=0.7)
    plt.title("Rectified EMG")
    plt.ylabel("Amplitude")

    plt.subplot(2, 1, 2)
    # Adjust for reduced samples
    rms_samples = min(samples // 200, rms_feature.shape[-1])
    plt.plot(rms_feature[channel, :rms_samples].rename(None).numpy(), linewidth=2)
    plt.title("RMS Envelope (200 sample window)")
    plt.xlabel("Windows")
    plt.ylabel("RMS Amplitude")

    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_004.png
   :alt: Rectified EMG, RMS Envelope (200 sample window)
   :srcset: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    RMS output shape: torch.Size([320, 102])




.. GENERATED FROM PYTHON SOURCE LINES 150-154

4. Composes: Chaining Transforms
---------------------------------
Combine multiple transforms into a preprocessing pipeline.
Uses torchvision.transforms.Compose under the hood.

.. GENERATED FROM PYTHON SOURCE LINES 154-168

.. code-block:: Python


    pipeline = Compose([
        Bandpass(low=20, high=450, fs=SAMPLING_FREQ, dim="time"),
        Rectify(),
        RMS(window_size=200, dim="time"),
    ])

    print(f"Compose: {pipeline}")

    # Apply entire pipeline
    processed = pipeline(emg)
    print(f"Input: {emg.names} {emg.shape}")
    print(f"Output: {processed.names} {processed.shape}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Compose: Compose(
        Bandpass(dim='time', low=20, high=450, fs=2044, order=4, Q=0.707)
        Rectify(dim='time')
        RMS(dim='time', window_size=200, stride=200)
    )
    Input: ('channel', 'time') torch.Size([320, 20440])
    Output: ('channel', 'time') torch.Size([320, 102])




.. GENERATED FROM PYTHON SOURCE LINES 169-172

5. Mean Absolute Value (MAV)
----------------------------
Another common EMG feature - moving average of rectified signal.

.. GENERATED FROM PYTHON SOURCE LINES 172-196

.. code-block:: Python


    from myoverse.transforms import MAV

    mav = MAV(window_size=200, dim="time")
    mav_feature = mav(rectified)

    # Compare RMS and MAV
    plt.figure(figsize=(12, 6))

    # Normalize for comparison
    rms_data = rms_feature[channel].rename(None)
    mav_data = mav_feature[channel].rename(None)
    rms_norm = (rms_data - rms_data.min()) / (rms_data.max() - rms_data.min())
    mav_norm = (mav_data - mav_data.min()) / (mav_data.max() - mav_data.min())

    n_windows = min(50, len(rms_norm))
    plt.plot(rms_norm[:n_windows].numpy(), label="RMS", linewidth=2)
    plt.plot(mav_norm[:n_windows].numpy(), label="MAV", linewidth=2, alpha=0.8)
    plt.title("RMS vs MAV Features (Normalized)")
    plt.xlabel("Windows")
    plt.ylabel("Normalized Amplitude")
    plt.legend()
    plt.show()




.. image-sg:: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_005.png
   :alt: RMS vs MAV Features (Normalized)
   :srcset: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_005.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 197-200

6. Lowpass vs Highpass
----------------------
Compare different filter types.

.. GENERATED FROM PYTHON SOURCE LINES 200-230

.. code-block:: Python


    from myoverse.transforms import Highpass, Lowpass

    lowpass = Lowpass(cutoff=50, fs=SAMPLING_FREQ, dim="time")
    highpass = Highpass(cutoff=50, fs=SAMPLING_FREQ, dim="time")

    low_filtered = lowpass(emg)
    high_filtered = highpass(emg)

    plt.figure(figsize=(12, 10))

    plt.subplot(3, 1, 1)
    plt.plot(emg[channel, :samples].rename(None).numpy())
    plt.title("Raw EMG")
    plt.ylabel("Amplitude")

    plt.subplot(3, 1, 2)
    plt.plot(low_filtered[channel, :samples].rename(None).numpy())
    plt.title("Lowpass Filtered (< 50 Hz)")
    plt.ylabel("Amplitude")

    plt.subplot(3, 1, 3)
    plt.plot(high_filtered[channel, :samples].rename(None).numpy())
    plt.title("Highpass Filtered (> 50 Hz)")
    plt.xlabel("Samples")
    plt.ylabel("Amplitude")

    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_006.png
   :alt: Raw EMG, Lowpass Filtered (< 50 Hz), Highpass Filtered (> 50 Hz)
   :srcset: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_006.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 231-234

7. Normalization
----------------
Z-score normalization for consistent scaling.

.. GENERATED FROM PYTHON SOURCE LINES 234-251

.. code-block:: Python


    from myoverse.transforms import ZScore

    # Z-score normalize each channel over time
    zscore = ZScore(dim="time")
    normalized = zscore(processed)

    processed_data = processed.rename(None)
    print(f"Before normalization:")
    print(f"\tMean: {float(processed_data.mean()):.4f}")
    print(f"\tStd:  {float(processed_data.std()):.4f}")

    normalized_data = normalized.rename(None)
    print(f"\nAfter normalization:")
    print(f"\tMean: {float(normalized_data.mean()):.6f}")
    print(f"\tStd:  {float(normalized_data.std()):.6f}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Before normalization:
            Mean: 0.5708
            Std:  0.0274

    After normalization:
            Mean: -0.000000
            Std:  0.995101




.. GENERATED FROM PYTHON SOURCE LINES 252-255

8. Data Augmentation
--------------------
Add noise and warping for training augmentation.

.. GENERATED FROM PYTHON SOURCE LINES 255-287

.. code-block:: Python


    from myoverse.transforms import GaussianNoise, MagnitudeWarp

    # Add Gaussian noise
    noise_aug = GaussianNoise(std=0.1)
    noisy = noise_aug(emg)

    # Magnitude warping
    warp_aug = MagnitudeWarp(sigma=0.2, n_knots=4, dim="time")
    warped = warp_aug(emg)

    plt.figure(figsize=(12, 10))

    plt.subplot(3, 1, 1)
    plt.plot(emg[channel, :samples].rename(None).numpy())
    plt.title("Original EMG")
    plt.ylabel("Amplitude")

    plt.subplot(3, 1, 2)
    plt.plot(noisy[channel, :samples].rename(None).numpy())
    plt.title("With Gaussian Noise")
    plt.ylabel("Amplitude")

    plt.subplot(3, 1, 3)
    plt.plot(warped[channel, :samples].rename(None).numpy())
    plt.title("With Magnitude Warping")
    plt.xlabel("Samples")
    plt.ylabel("Amplitude")

    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_007.png
   :alt: Original EMG, With Gaussian Noise, With Magnitude Warping
   :srcset: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_007.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 288-291

9. Multi-feature Extraction
---------------------------
Extract multiple features using Stack.

.. GENERATED FROM PYTHON SOURCE LINES 291-313

.. code-block:: Python


    from myoverse.transforms import Stack

    # Create multiple feature extractors
    feature_pipeline = Compose([
        Bandpass(low=20, high=450, fs=SAMPLING_FREQ, dim="time"),
        Rectify(),
    ])

    # Apply bandpass + rectify first
    preprocessed = feature_pipeline(emg)

    # Then extract multiple features
    features = Stack({
        "rms": RMS(window_size=200, dim="time"),
        "mav": MAV(window_size=200, dim="time"),
        "var": myoverse.transforms.VAR(window_size=200, dim="time"),
    }, dim="feature")

    multi_features = features(preprocessed)
    print(f"Multi-feature output: {multi_features.names} {multi_features.shape}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Multi-feature output: ('feature', 'channel', 'time') torch.Size([3, 320, 102])




.. GENERATED FROM PYTHON SOURCE LINES 314-317

10. GPU Acceleration
--------------------
Move data to GPU for faster processing.

.. GENERATED FROM PYTHON SOURCE LINES 317-329

.. code-block:: Python


    if torch.cuda.is_available():
        # Move to GPU
        emg_gpu = emg.cuda()
        print(f"EMG on GPU: {emg_gpu.device}")

        # Apply pipeline on GPU
        processed_gpu = pipeline(emg_gpu)
        print(f"Processed on GPU: {processed_gpu.device}")
    else:
        print("CUDA not available - using CPU")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    CUDA not available - using CPU




.. GENERATED FROM PYTHON SOURCE LINES 330-333

11. Creating Custom Transforms
------------------------------
Extend the Transform base class for custom processing.

.. GENERATED FROM PYTHON SOURCE LINES 333-416

.. code-block:: Python


    from myoverse.transforms import Transform

    class MedianFilter(Transform):
        """Custom median filter transform using PyTorch.

        Parameters
        ----------
        kernel_size : int
            Size of the median filter kernel. Must be odd.
        dim : str
            Dimension to filter along.
        """

        def __init__(self, kernel_size: int = 5, dim: str = "time", **kwargs):
            super().__init__(dim=dim, **kwargs)
            if kernel_size % 2 == 0:
                raise ValueError("Kernel size must be odd")
            self.kernel_size = kernel_size

        def _apply(self, x: torch.Tensor) -> torch.Tensor:
            from myoverse.transforms.base import get_dim_index
            dim_idx = get_dim_index(x, self.dim)
            names = x.names

            x = x.rename(None)

            # Unfold to get sliding windows
            x_unfolded = x.unfold(dim_idx, self.kernel_size, 1)

            # Compute median over the last dimension (the window)
            result = x_unfolded.median(dim=-1).values

            # Pad to maintain size
            pad_total = self.kernel_size - 1
            pad_before = pad_total // 2
            pad_after = pad_total - pad_before

            # Move target dim to last position for padding
            result = result.movedim(dim_idx, -1)
            original_shape = result.shape

            # F.pad with mode='replicate' requires 3D+ input
            # Reshape to 3D: (batch, 1, time)
            result = result.reshape(-1, 1, result.shape[-1])
            result = torch.nn.functional.pad(result, (pad_before, pad_after), mode='replicate')

            # Restore original shape and move dim back
            result = result.reshape(*original_shape[:-1], -1)
            result = result.movedim(-1, dim_idx)

            if names[0] is not None:
                result = result.rename(*names)

            return result

    # Use in a pipeline
    custom_pipeline = Compose([
        Bandpass(low=20, high=450, fs=SAMPLING_FREQ, dim="time"),
        MedianFilter(kernel_size=11, dim="time"),
        ZScore(dim="time"),
    ])

    custom_output = custom_pipeline(emg)
    print(f"Custom pipeline output: {custom_output.names} {custom_output.shape}")

    # Visualize
    plt.figure(figsize=(12, 8))

    plt.subplot(2, 1, 1)
    plt.plot(emg[channel, :samples].rename(None).numpy())
    plt.title("Raw EMG")
    plt.ylabel("Amplitude")

    plt.subplot(2, 1, 2)
    plt.plot(custom_output[channel, :samples].rename(None).numpy())
    plt.title("Custom Compose (Bandpass + Median + ZScore)")
    plt.xlabel("Samples")
    plt.ylabel("Amplitude")

    plt.tight_layout()
    plt.show()




.. image-sg:: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_008.png
   :alt: Raw EMG, Custom Compose (Bandpass + Median + ZScore)
   :srcset: /auto_examples/02_filters/images/sphx_glr_2_temporal_filters_008.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Custom pipeline output: ('channel', 'time') torch.Size([320, 20440])




.. GENERATED FROM PYTHON SOURCE LINES 417-432

Summary
-------
Key temporal transforms:

- **Bandpass/Lowpass/Highpass/Notch** - FFT-based frequency filtering
- **Rectify** - Full-wave rectification
- **RMS/MAV/VAR** - Sliding window feature extraction
- **ZScore/MinMax** - Normalization
- **GaussianNoise/MagnitudeWarp/TimeWarp** - Augmentation

All transforms:
- Work with PyTorch named tensors
- Are dimension-aware via the `dim` parameter
- Run on both CPU and GPU
- Can be combined with torchvision.transforms.Compose (or Compose)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 9.975 seconds)

**Estimated memory usage:**  820 MB


.. _sphx_glr_download_auto_examples_02_filters_2_temporal_filters.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 2_temporal_filters.ipynb <2_temporal_filters.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 2_temporal_filters.py <2_temporal_filters.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: 2_temporal_filters.zip <2_temporal_filters.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
